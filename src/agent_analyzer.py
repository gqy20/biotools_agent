"""åŸºäºClaude Code SDKçš„ä»£ç†åˆ†æå™¨

ä½¿ç”¨å¤šä¸ªä¸“ä¸šä»£ç†è¿›è¡Œç”Ÿç‰©ä¿¡æ¯å­¦å·¥å…·çš„æ·±åº¦åˆ†æ
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

from claude_agent_sdk import ClaudeSDKClient, ClaudeAgentOptions

from .config import config_manager
from .models import (
    BioToolAnalysis,
    DataRequirements,
    DeploymentInfo,
    FunctionalityInfo,
    PerformanceInfo,
    Publication,
    TestingInfo,
    UsageInfo,
    ProjectArchitecture,
    CodeQualityInfo,
    SecurityAnalysis,
)
from .agent_definitions import PROJECT_AGENTS, ANALYSIS_TASKS


class AgentAIAnalyzer:
    """åŸºäºClaude Code SDKçš„AIåˆ†æå™¨"""

    def __init__(self, config_override: dict = None):
        """åˆå§‹åŒ–ä»£ç†åˆ†æå™¨"""
        self.config = config_override or config_manager.config
        self.use_file_agents = getattr(self.config, 'use_file_agents', True)
        self.fallback_to_programmatic = getattr(self.config, 'fallback_to_programmatic', True)

        self.options = self._create_agent_options()
        print("âœ… Claude Code SDKä»£ç†åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def _create_agent_options(self, repo_path: Optional[Path] = None) -> ClaudeAgentOptions:
        """åˆ›å»ºä»£ç†é…ç½®é€‰é¡¹"""
        # æ­£ç¡®è®¿é—®åµŒå¥—é…ç½®
        claude_config = getattr(self.config, 'claude_sdk', self.config)

        # åŸºç¡€é…ç½®
        options = ClaudeAgentOptions(
            # å…è®¸ä½¿ç”¨çš„å·¥å…·
            allowed_tools=[
                "Read", "Write", "Edit", "Glob", "Grep",
                "Bash", "WebSearch", "WebFetch"
            ],

            # ä¼˜å…ˆä½¿ç”¨ç¨‹åºåŒ–å®šä¹‰ï¼ˆç°åœ¨PROJECT_AGENTSå·²ç»æ˜¯AgentDefå®ä¾‹ï¼‰
            agents=PROJECT_AGENTS if self.fallback_to_programmatic else None,

            # æ¨¡å‹é…ç½®
            model=getattr(claude_config, 'claude_model', 'sonnet'),
            max_turns=getattr(claude_config, 'max_turns', 10),

            # æƒé™é…ç½®
            permission_mode=getattr(claude_config, 'permission_mode', 'acceptEdits'),

            # å·¥ä½œç›®å½•è®¾ç½®ï¼ˆå¦‚æœæä¾›ï¼‰
            cwd=str(repo_path) if repo_path else None,
        )

        return options

    async def analyze_repository_content(
        self, repo_path: Path, repo_info, authors
    ) -> BioToolAnalysis:
        """ä½¿ç”¨ä»£ç†åˆ†æä»“åº“å†…å®¹"""

        print("ğŸš€ å¼€å§‹Claudeä»£ç†æ·±åº¦åˆ†æä»“åº“å†…å®¹...")
        print(f"ğŸ“‚ åˆ†æä»“åº“è·¯å¾„: {repo_path}")
        print(f"ğŸ¤– ä½¿ç”¨ {len(PROJECT_AGENTS)} ä¸ªä¸“ä¸šä»£ç†è¿›è¡Œåˆ†æ")

        try:
            # åˆ›å»ºåŒ…å«å·¥ä½œç›®å½•çš„options
            options_with_cwd = self._create_agent_options(repo_path)

            async with ClaudeSDKClient(options=options_with_cwd) as client:
                # æ„å»ºåˆ†æä»»åŠ¡
                analysis_result = await self._execute_parallel_analysis(
                    client, repo_info, authors
                )

                # è½¬æ¢ä¸ºBioToolAnalysiså¯¹è±¡
                return self._convert_to_biotools_analysis(
                    analysis_result, repo_info, authors
                )

        except Exception as e:
            print(f"âŒ Claudeä»£ç†åˆ†æå¤±è´¥: {e}")
            print("ğŸ”„ é™çº§åˆ°åŸºç¡€åˆ†æ...")
            return self._create_fallback_analysis(repo_info, authors)

    async def _execute_parallel_analysis(
        self, client: ClaudeSDKClient, repo_info, authors
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå¹¶è¡Œåˆ†æä»»åŠ¡"""

        # æ„å»ºé¡¹ç›®ä¿¡æ¯æ‘˜è¦
        author_names = [author.name for author in authors]
        project_info = f"""
## é¡¹ç›®åŸºç¡€ä¿¡æ¯
- é¡¹ç›®åç§°: {repo_info.name}
- é¡¹ç›®URL: {repo_info.url}
- ä¸»è¦è¯­è¨€: {repo_info.language}
- Staræ•°é‡: {repo_info.stars}
- Forkæ•°é‡: {repo_info.forks}
- è®¸å¯è¯: {repo_info.license}
- é¡¹ç›®æè¿°: {repo_info.description}

## ä½œè€…ä¿¡æ¯
- ä¸»è¦ä½œè€…: {', '.join(author_names)}

è¯·åŸºäºè¿™äº›ä¿¡æ¯å’Œå®é™…ä»£ç è¿›è¡Œæ·±åº¦åˆ†æã€‚
"""

        analysis_results = {}

        # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªåˆ†æä»»åŠ¡
        tasks = []
        for task_config in ANALYSIS_TASKS:
            task_prompt = f"""
            è¯·ä½¿ç”¨{task_config['agent']}ä»£ç†æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š

            {task_config['description']}

            {project_info}

            è¯·é‡ç‚¹å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼š
            {', '.join(task_config['focus'])}

            è¯·æä¾›è¯¦ç»†çš„ç»“æ„åŒ–åˆ†æç»“æœï¼Œä½¿ç”¨JSONæ ¼å¼è¾“å‡ºã€‚
            """

            task = self._execute_single_task(
                client, task_config['agent'], task_prompt
            )
            tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        try:
            task_results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†ç»“æœ
            for i, result in enumerate(task_results):
                if isinstance(result, Exception):
                    print(f"âš ï¸ ä»»åŠ¡ {ANALYSIS_TASKS[i]['agent']} å¤±è´¥: {result}")
                    # ä½¿ç”¨ç©ºç»“æœç»§ç»­
                    analysis_results[ANALYSIS_TASKS[i]['agent']] = {}
                else:
                    analysis_results[ANALYSIS_TASKS[i]['agent']] = result

        except Exception as e:
            print(f"âŒ å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            # å°è¯•ä¸²è¡Œæ‰§è¡Œä½œä¸ºå¤‡é€‰
            return await self._execute_sequential_analysis(client, repo_info, authors)

        return analysis_results

    async def _execute_single_task(
        self, client: ClaudeSDKClient, agent_name: str, prompt: str
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªåˆ†æä»»åŠ¡"""

        task_prompt = f"""
        è¯·ä½¿ç”¨{agent_name}ä»£ç†è¿›è¡Œåˆ†æã€‚

        {prompt}

        è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼Œç¡®ä¿ç»“æœå¯ä»¥è¢«Pythonè§£æã€‚
        å¦‚æœæŸä¸ªå­—æ®µæ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·çœç•¥è¯¥å­—æ®µæˆ–ä½¿ç”¨ç©ºæ•°ç»„/ç©ºå­—ç¬¦ä¸²ã€‚
        """

        result_data = {}

        try:
            # ä¿®å¤ï¼šç›´æ¥ await è°ƒç”¨ï¼Œè€Œä¸æ˜¯ async for
            result = await client.query(task_prompt)

            # å¤„ç†è¿”å›ç»“æœ
            if hasattr(result, 'content'):
                content = result.content

                # å°è¯•è§£æJSONç»“æœ
                if isinstance(content, str):
                    try:
                        # æå–JSONéƒ¨åˆ†
                        json_start = content.find('{')
                        json_end = content.rfind('}') + 1

                        if json_start >= 0 and json_end > json_start:
                            json_content = content[json_start:json_end]
                            parsed_data = json.loads(json_content)
                            result_data.update(parsed_data)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")

            # æ£€æŸ¥å…¶ä»–å¯èƒ½çš„å±æ€§
            elif hasattr(result, 'text'):
                content = result.text
                if isinstance(content, str):
                    try:
                        json_start = content.find('{')
                        json_end = content.rfind('}') + 1
                        if json_start >= 0 and json_end > json_start:
                            json_content = content[json_start:json_end]
                            parsed_data = json.loads(json_content)
                            result_data.update(parsed_data)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")

            elif hasattr(result, 'response'):
                content = result.response
                if isinstance(content, str):
                    try:
                        json_start = content.find('{')
                        json_end = content.rfind('}') + 1
                        if json_start >= 0 and json_end > json_start:
                            json_content = content[json_start:json_end]
                            parsed_data = json.loads(json_content)
                            result_data.update(parsed_data)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")

        except Exception as e:
            print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")

        return result_data

    async def _execute_sequential_analysis(
        self, client: ClaudeSDKClient, repo_info, authors
    ) -> Dict[str, Any]:
        """ä¸²è¡Œæ‰§è¡Œåˆ†æä»»åŠ¡ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""

        print("ğŸ”„ ä½¿ç”¨ä¸²è¡Œæ¨¡å¼æ‰§è¡Œåˆ†æä»»åŠ¡...")
        analysis_results = {}

        for task_config in ANALYSIS_TASKS:
            try:
                print(f"ğŸ“Š æ‰§è¡Œä»»åŠ¡: {task_config['description']}")

                task_prompt = f"""
                è¯·åˆ†æè¿™ä¸ªç”Ÿç‰©ä¿¡æ¯å­¦å·¥å…·é¡¹ç›®ï¼š{repo_info.name}

                {task_config['description']}

                è¯·æä¾›ç»“æ„åŒ–çš„JSONæ ¼å¼åˆ†æç»“æœã€‚
                """

                result = await self._execute_single_task(
                    client, task_config['agent'], task_prompt
                )
                analysis_results[task_config['agent']] = result

            except Exception as e:
                print(f"âŒ ä»»åŠ¡ {task_config['agent']} å¤±è´¥: {e}")
                analysis_results[task_config['agent']] = {}

        return analysis_results

    def _convert_to_biotools_analysis(
        self, agent_results: Dict[str, Any], repo_info, authors
    ) -> BioToolAnalysis:
        """å°†ä»£ç†ç»“æœè½¬æ¢ä¸ºBioToolAnalysiså¯¹è±¡"""

        # åˆå¹¶æ‰€æœ‰ä»£ç†ç»“æœ
        merged_result = {}
        for agent_name, result in agent_results.items():
            if result:
                merged_result.update(result)

        # è§£æåŠŸèƒ½ä¿¡æ¯
        func_data = merged_result.get('functionality', {})
        functionality = FunctionalityInfo(
            main_purpose=func_data.get('main_purpose', 'ç”Ÿç‰©ä¿¡æ¯å­¦å·¥å…·'),
            key_features=func_data.get('key_features', []),
            input_formats=func_data.get('input_formats', []),
            output_formats=func_data.get('output_formats', []),
            dependencies=func_data.get('dependencies', [])
        )

        # è§£æä½¿ç”¨ä¿¡æ¯
        usage_data = merged_result.get('usage', {})
        usage = UsageInfo(
            installation=usage_data.get('installation', 'å‚è€ƒé¡¹ç›®æ–‡æ¡£'),
            basic_usage=usage_data.get('basic_usage', 'å‚è€ƒé¡¹ç›®æ–‡æ¡£'),
            examples=usage_data.get('examples', []),
            parameters=usage_data.get('parameters', [])
        )

        # è§£ææ€§èƒ½ä¿¡æ¯
        perf_data = merged_result.get('performance', {})
        performance = PerformanceInfo(
            time_complexity=perf_data.get('time_complexity', ''),
            space_complexity=perf_data.get('space_complexity', ''),
            parallelization=perf_data.get('parallelization', ''),
            resource_usage=perf_data.get('resource_usage', ''),
            optimization_suggestions=perf_data.get('optimization_suggestions', [])
        )

        # è§£æéƒ¨ç½²ä¿¡æ¯
        deploy_data = merged_result.get('deployment', {})
        deployment = DeploymentInfo(
            installation_methods=deploy_data.get('installation_methods', []),
            system_requirements=deploy_data.get('system_requirements', []),
            container_support=deploy_data.get('container_support', []),
            cloud_deployment=deploy_data.get('cloud_deployment', []),
            configuration_files=deploy_data.get('configuration_files', [])
        )

        # è§£ææµ‹è¯•ä¿¡æ¯
        test_data = merged_result.get('testing', {})
        testing = TestingInfo(
            test_commands=test_data.get('test_commands', []),
            test_data_sources=test_data.get('test_data_sources', []),
            example_datasets=test_data.get('example_datasets', []),
            validation_methods=test_data.get('validation_methods', []),
            benchmark_datasets=test_data.get('benchmark_datasets', [])
        )

        # è§£ææ•°æ®éœ€æ±‚
        data_data = merged_result.get('data_requirements', {})
        data_requirements = DataRequirements(
            required_inputs=data_data.get('required_inputs', []),
            optional_inputs=data_data.get('optional_inputs', []),
            data_formats=data_data.get('data_formats', []),
            file_size_limits=data_data.get('file_size_limits', ''),
            preprocessing_steps=data_data.get('preprocessing_steps', [])
        )

        # è§£æå‘è¡¨æ–‡ç« 
        pub_data = merged_result.get('publications', [])
        publications = [
            Publication(
                title=pub.get('title', ''),
                authors=pub.get('authors', []),
                journal=pub.get('journal'),
                year=pub.get('year'),
                doi=pub.get('doi'),
                pmid=pub.get('pmid')
            )
            for pub in pub_data
            if pub.get('title')
        ]

        # è§£ææ¶æ„ä¿¡æ¯
        arch_data = merged_result.get('architecture', {})
        architecture = ProjectArchitecture(
            programming_languages=arch_data.get('programming_languages', []),
            frameworks=arch_data.get('frameworks', []),
            directory_structure=arch_data.get('directory_structure', {}),
            main_components=arch_data.get('main_components', []),
            entry_points=arch_data.get('entry_points', []),
            config_files=arch_data.get('config_files', []),
            test_structure=arch_data.get('test_structure', {})
        )

        # è§£æå®‰å…¨ä¿¡æ¯
        security_data = merged_result.get('security_analysis', {})
        if security_data:
            security = SecurityAnalysis(
                vulnerabilities=security_data.get('vulnerabilities', []),
                sensitive_data=security_data.get('sensitive_data', []),
                dependencies=security_data.get('dependencies', [])
            )
        else:
            security = None

        return BioToolAnalysis(
            repository=repo_info,
            authors=authors,
            publications=publications,
            functionality=functionality,
            usage=usage,
            architecture=architecture,
            code_quality=merged_result.get('code_quality'),
            performance=performance,
            bioinformatics_expertise=merged_result.get('bioinformatics_expertise'),
            usability=merged_result.get('usability'),
            deployment=deployment,
            testing=testing,
            data_requirements=data_requirements,
            security=security,
            analysis_timestamp=datetime.now().isoformat(),
        )

    def _create_fallback_analysis(self, repo_info, authors) -> BioToolAnalysis:
        """åˆ›å»ºé™çº§åˆ†æç»“æœ"""
        return BioToolAnalysis(
            repository=repo_info,
            authors=authors,
            publications=[],
            functionality=FunctionalityInfo(
                main_purpose="ç”Ÿç‰©ä¿¡æ¯å­¦å·¥å…·",
                key_features=[],
                input_formats=[],
                output_formats=[],
                dependencies=[]
            ),
            usage=UsageInfo(
                installation="å‚è€ƒé¡¹ç›®æ–‡æ¡£",
                basic_usage="å‚è€ƒé¡¹ç›®æ–‡æ¡£",
                examples=[],
                parameters=[]
            ),
            deployment=None,
            testing=None,
            data_requirements=None,
            analysis_timestamp=datetime.now().isoformat(),
        )

    async def _security_validation_hook(self, tool_call):
        """å®‰å…¨éªŒè¯Hook"""
        # åŸºæœ¬å®‰å…¨æ£€æŸ¥
        dangerous_operations = ['rm -rf', 'sudo', 'chmod 777']
        tool_args = str(tool_call.get('arguments', ''))

        for dangerous_op in dangerous_operations:
            if dangerous_op in tool_args:
                print(f"âš ï¸ å®‰å…¨è­¦å‘Š: æ£€æµ‹åˆ°æ½œåœ¨å±é™©æ“ä½œ: {dangerous_op}")
                return False

        return True

    async def _result_quality_hook(self, tool_result):
        """ç»“æœè´¨é‡æ£€æŸ¥Hook"""
        # åŸºæœ¬ç»“æœéªŒè¯
        if hasattr(tool_result, 'content'):
            content = str(tool_result.content)
            if len(content) > 100000:  # é™åˆ¶ç»“æœå¤§å°
                print("âš ï¸ ç»“æœè¿‡å¤§ï¼Œå°†è¢«æˆªæ–­")
                return False

        return True