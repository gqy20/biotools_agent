"""LLMå®¢æˆ·ç«¯ - å‚è€ƒPhase2ä»£ç å®ç°"""

import json
import time
from typing import List, Dict, Any, Optional

from openai import OpenAI

from .config import config_manager


class LLMClient:
    """LLMå®¢æˆ·ç«¯ï¼Œå°è£…å¤§æ¨¡å‹è°ƒç”¨"""
    
    def __init__(self, config_manager_instance=None):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        self.config_manager = config_manager_instance or config_manager
        self.config = self.config_manager.get_openai_config()
        self.model = self.config_manager.config.openai_model
        self.client = OpenAI(**self.config)
    
    async def chat_completion(
        self, 
        messages: List[Dict[str, str]], 
        max_tokens: int = 2000,
        temperature: float = 0.1,
        timeout: int = 60
    ) -> str:
        """
        å‘é€èŠå¤©å®Œæˆè¯·æ±‚
        
        å‚æ•°ç±»ä¼¼Phase2ä»£ç ä¸­çš„è°ƒç”¨æ–¹å¼
        """
        try:
            print(f"ğŸ¤– è°ƒç”¨LLMæ¨¡å‹: {self.model}")
            print("ğŸ“¤ å‘é€è¯·æ±‚...")
            
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                timeout=timeout,
                extra_body={"enable_thinking": False}  # ModelScopeç‰¹å®šå‚æ•°
            )
            
            elapsed = time.time() - start_time
            result = response.choices[0].message.content.strip()
            
            print(f"ğŸ“¥ æ”¶åˆ°å“åº”ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
            print(f"ğŸ“ å“åº”é•¿åº¦: {len(result)} å­—ç¬¦")
            
            return result
            
        except Exception as e:
            print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            raise e
    
    def sync_chat_completion(
        self,
        messages: List[Dict[str, str]], 
        max_tokens: int = 2000,
        temperature: float = 0.1,
        timeout: int = 60
    ) -> str:
        """
        åŒæ­¥ç‰ˆæœ¬çš„èŠå¤©å®Œæˆè¯·æ±‚
        """
        try:
            print(f"ğŸ¤– è°ƒç”¨LLMæ¨¡å‹: {self.model}")
            print("ğŸ“¤ å‘é€è¯·æ±‚...")
            
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                timeout=timeout,
                extra_body={"enable_thinking": False}  # ModelScopeç‰¹å®šå‚æ•°
            )
            
            elapsed = time.time() - start_time
            result = response.choices[0].message.content.strip()
            
            print(f"ğŸ“¥ æ”¶åˆ°å“åº”ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
            print(f"ğŸ“ å“åº”é•¿åº¦: {len(result)} å­—ç¬¦")
            
            return result
            
        except Exception as e:
            print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            raise e
    
    def extract_json_from_response(self, response: str) -> Optional[Dict[str, Any]]:
        """ä»å“åº”ä¸­æå–JSONæ•°æ®"""
        try:
            # æŸ¥æ‰¾JSONéƒ¨åˆ†
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_content = response[json_start:json_end]
                print(f"ğŸ“Š æå–JSONå†…å®¹: {len(json_content)} å­—ç¬¦")
                return json.loads(json_content)
            else:
                print("âš ï¸ å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆJSON")
                return None
                
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            return None
