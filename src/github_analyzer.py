"""GitHubä»“åº“åˆ†æå™¨"""

import os
import re
from pathlib import Path
from typing import Dict, List, Optional

import requests
from git import Repo

from .config import config_manager
from .models import AuthorInfo, ProjectArchitecture, RepositoryInfo, SecurityAnalysis


class GitHubAnalyzer:
    """GitHubä»“åº“åˆ†æå™¨"""

    def __init__(self, tmp_dir: str = None):
        self.tmp_dir = Path(tmp_dir or config_manager.config.tmp_dir)
        self.tmp_dir.mkdir(exist_ok=True)
        self.headers = config_manager.get_github_headers()

    def clone_repository(self, repo_url: str) -> Path:
        """å…‹éš†GitHubä»“åº“åˆ°ä¸´æ—¶ç›®å½•"""
        repo_name = self._extract_repo_name(repo_url)
        clone_path = self.tmp_dir / repo_name

        # å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
        if clone_path.exists():
            import shutil

            shutil.rmtree(clone_path)

        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„
        if repo_url.startswith("file://"):
            local_path = Path(repo_url[7:])  # ç§»é™¤ "file://" å‰ç¼€
            if local_path.exists():
                # å¤åˆ¶æœ¬åœ°ç›®å½•åˆ°ä¸´æ—¶ç›®å½•
                shutil.copytree(local_path, clone_path)
                print(f"âœ… æˆåŠŸå¤åˆ¶æœ¬åœ°ä»“åº“åˆ°: {clone_path}")
                return clone_path
            else:
                raise RuntimeError(f"æœ¬åœ°è·¯å¾„ä¸å­˜åœ¨: {local_path}")
        else:
            try:
                repo = Repo.clone_from(repo_url, clone_path)
                return clone_path
            except Exception as e:
                raise Exception(f"å…‹éš†ä»“åº“å¤±è´¥: {e}")

    def analyze_repository_info(self, repo_url: str) -> RepositoryInfo:
        """åˆ†æä»“åº“åŸºç¡€ä¿¡æ¯"""
        owner, repo_name = self._parse_github_url(repo_url)

        # è°ƒç”¨GitHub APIè·å–ä»“åº“ä¿¡æ¯
        api_url = f"https://api.github.com/repos/{owner}/{repo_name}"

        try:
            # é¦–å…ˆå°è¯•å¸¦è®¤è¯çš„è°ƒç”¨
            response = requests.get(api_url, headers=self.headers, timeout=10)

            # å¦‚æœè®¤è¯å¤±è´¥ï¼Œå°è¯•æ— è®¤è¯è°ƒç”¨
            if response.status_code == 401:
                print("âš ï¸ GitHubè®¤è¯å¤±è´¥ï¼Œå°è¯•æ— è®¤è¯è®¿é—®...")
                response = requests.get(api_url, timeout=10)

            if response.status_code == 200:
                data = response.json()
                print(
                    f"âœ… æˆåŠŸè·å–GitHubä»“åº“ä¿¡æ¯: {data.get('stargazers_count')} stars"
                )
                return RepositoryInfo(
                    name=data.get("name", repo_name),
                    url=repo_url,
                    description=data.get("description"),
                    language=data.get("language"),
                    stars=data.get("stargazers_count", 0),
                    forks=data.get("forks_count", 0),
                    license=(
                        data.get("license", {}).get("name")
                        if data.get("license")
                        else None
                    ),
                )
            else:
                print(f"âš ï¸ GitHub APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                # APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ä¿¡æ¯
                return RepositoryInfo(name=repo_name, url=repo_url)
        except Exception as e:
            print(f"âš ï¸ è·å–ä»“åº“ä¿¡æ¯å¤±è´¥: {e}")
            # å¼‚å¸¸æƒ…å†µï¼Œä½¿ç”¨åŸºç¡€ä¿¡æ¯
            return RepositoryInfo(name=repo_name, url=repo_url)
            return RepositoryInfo(name=repo_name, url=repo_url)

    def extract_authors_from_repo(self, repo_path: Path) -> List[AuthorInfo]:
        """ä»ä»“åº“ä¸­æå–ä½œè€…ä¿¡æ¯"""
        authors = []

        # 1. ä»READMEæ–‡ä»¶ä¸­æå–ä½œè€…ä¿¡æ¯
        readme_authors = self._extract_authors_from_readme(repo_path)
        authors.extend(readme_authors)

        # 2. ä»setup.pyæˆ–pyproject.tomlä¸­æå–ä½œè€…ä¿¡æ¯
        setup_authors = self._extract_authors_from_setup_files(repo_path)
        authors.extend(setup_authors)

        # 3. ä»Gitæäº¤è®°å½•ä¸­æå–ä½œè€…ä¿¡æ¯
        git_authors = self._extract_authors_from_git(repo_path)
        authors.extend(git_authors)

        # å»é‡å¤„ç†
        unique_authors = self._deduplicate_authors(authors)

        return unique_authors

    def analyze_project_architecture(self, repo_path: Path) -> ProjectArchitecture:
        """åˆ†æé¡¹ç›®æ¶æ„"""
        # 1. è¯†åˆ«ä¸»è¦ç¼–ç¨‹è¯­è¨€
        programming_languages = self._detect_programming_languages(repo_path)

        # 2. è¯†åˆ«æ¡†æ¶å’Œåº“
        frameworks = self._detect_frameworks(repo_path)

        # 3. åˆ†æç›®å½•ç»“æ„
        directory_structure = self._analyze_directory_structure(repo_path)

        # 4. è¯†åˆ«ä¸»è¦ç»„ä»¶
        main_components = self._identify_main_components(repo_path)

        # 5. è¯†åˆ«å…¥å£ç‚¹
        entry_points = self._identify_entry_points(repo_path)

        # 6. è¯†åˆ«é…ç½®æ–‡ä»¶
        config_files = self._identify_config_files(repo_path)

        # 7. è¯†åˆ«æµ‹è¯•ç»“æ„
        test_structure = self._analyze_test_structure(repo_path)

        return ProjectArchitecture(
            programming_languages=programming_languages,
            frameworks=frameworks,
            directory_structure=directory_structure,
            main_components=main_components,
            entry_points=entry_points,
            config_files=config_files,
            test_structure=test_structure,
        )

    def read_file_content(self, repo_path: Path, filename: str) -> Optional[str]:
        """è¯»å–æŒ‡å®šæ–‡ä»¶å†…å®¹"""
        file_patterns = [
            filename,
            filename.upper(),
            filename.lower(),
            f"{filename}.md",
            f"{filename.upper()}.md",
            f"{filename.lower()}.md",
            f"{filename}.txt",
            f"{filename.upper()}.txt",
            f"{filename.lower()}.txt",
        ]

        for pattern in file_patterns:
            file_path = repo_path / pattern
            if file_path.exists() and file_path.is_file():
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        return f.read()
                except UnicodeDecodeError:
                    try:
                        with open(file_path, "r", encoding="latin-1") as f:
                            return f.read()
                    except Exception:
                        continue

        return None

    def _extract_repo_name(self, repo_url: str) -> str:
        """ä»URLä¸­æå–ä»“åº“åç§°"""
        return repo_url.rstrip("/").split("/")[-1].replace(".git", "")

    def _parse_github_url(self, repo_url: str) -> tuple:
        """è§£æGitHub URLè·å–ownerå’Œrepoåç§°"""
        # å¤„ç†ä¸åŒæ ¼å¼çš„GitHub URL
        if "github.com" in repo_url:
            parts = (
                repo_url.replace("https://", "")
                .replace("http://", "")
                .replace(".git", "")
                .split("/")
            )
            if len(parts) >= 3:
                return parts[1], parts[2]

        raise ValueError(f"æ— æ•ˆçš„GitHub URL: {repo_url}")

    def _extract_authors_from_readme(self, repo_path: Path) -> List[AuthorInfo]:
        """ä»READMEæ–‡ä»¶ä¸­æå–ä½œè€…ä¿¡æ¯"""
        authors = []
        readme_content = self.read_file_content(repo_path, "README")

        if not readme_content:
            return authors

        # æŸ¥æ‰¾ä½œè€…ç›¸å…³çš„æ¨¡å¼
        author_patterns = [
            r"(?i)author[s]?[:\-\s]*([^\n]+)",
            r"(?i)contributor[s]?[:\-\s]*([^\n]+)",
            r"(?i)developed?\s+by[:\-\s]*([^\n]+)",
            r"(?i)created?\s+by[:\-\s]*([^\n]+)",
            r"(?i)maintainer[s]?[:\-\s]*([^\n]+)",
        ]

        for pattern in author_patterns:
            matches = re.findall(pattern, readme_content)
            for match in matches:
                # æ¸…ç†å’Œè§£æä½œè€…ä¿¡æ¯
                author_text = match.strip()
                if author_text and len(author_text) < 100:  # é¿å…æå–è¿‡é•¿çš„æ–‡æœ¬
                    author_info = self._parse_author_text(author_text)
                    if author_info:
                        authors.append(author_info)

        return authors

    def _extract_authors_from_setup_files(self, repo_path: Path) -> List[AuthorInfo]:
        """ä»setupæ–‡ä»¶ä¸­æå–ä½œè€…ä¿¡æ¯"""
        authors = []

        # æ£€æŸ¥setup.py
        setup_py_path = repo_path / "setup.py"
        if setup_py_path.exists():
            setup_content = self.read_file_content(repo_path, "setup.py")
            if setup_content:
                author_matches = re.findall(
                    r'author\s*=\s*["\']([^"\']+)["\']', setup_content
                )
                for author in author_matches:
                    authors.append(AuthorInfo(name=author.strip()))

        # æ£€æŸ¥pyproject.toml
        pyproject_path = repo_path / "pyproject.toml"
        if pyproject_path.exists():
            pyproject_content = self.read_file_content(repo_path, "pyproject.toml")
            if pyproject_content:
                author_matches = re.findall(
                    r'name\s*=\s*["\']([^"\']+)["\']', pyproject_content
                )
                for author in author_matches:
                    authors.append(AuthorInfo(name=author.strip()))

        return authors

    def _extract_authors_from_git(self, repo_path: Path) -> List[AuthorInfo]:
        """ä»Gitæäº¤è®°å½•ä¸­æå–ä½œè€…ä¿¡æ¯"""
        authors = []

        try:
            repo = Repo(repo_path)
            commits = list(repo.iter_commits(max_count=100))  # åªæ£€æŸ¥æœ€è¿‘100æ¬¡æäº¤

            author_set = set()
            for commit in commits:
                author_name = commit.author.name
                author_email = commit.author.email

                if author_name and author_name not in author_set:
                    author_set.add(author_name)
                    authors.append(
                        AuthorInfo(
                            name=author_name,
                            email=author_email if "@" in author_email else None,
                        )
                    )

        except Exception as e:
            print(f"âš ï¸ ä»Gitè®°å½•æå–ä½œè€…ä¿¡æ¯å¤±è´¥: {e}")

        return authors

    def _parse_author_text(self, text: str) -> Optional[AuthorInfo]:
        """è§£æä½œè€…æ–‡æœ¬ä¿¡æ¯"""
        # ç§»é™¤å¸¸è§çš„æ ‡è®°ç¬¦å·
        cleaned_text = re.sub(r"[*\[\](){}]", "", text).strip()

        # æå–é‚®ç®±
        email_match = re.search(
            r"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})", cleaned_text
        )
        email = email_match.group(1) if email_match else None

        # ç§»é™¤é‚®ç®±åçš„åç§°
        name = re.sub(
            r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", "", cleaned_text
        ).strip()
        name = re.sub(r"[<>]", "", name).strip()

        if name and len(name) > 1:
            return AuthorInfo(name=name, email=email)

        return None

    def _deduplicate_authors(self, authors: List[AuthorInfo]) -> List[AuthorInfo]:
        """å»é‡ä½œè€…ä¿¡æ¯"""
        seen_names = set()
        unique_authors = []

        for author in authors:
            # æ ‡å‡†åŒ–åç§°è¿›è¡Œæ¯”è¾ƒ
            normalized_name = author.name.lower().strip()
            if normalized_name not in seen_names and len(normalized_name) > 1:
                seen_names.add(normalized_name)
                unique_authors.append(author)

        return unique_authors[:10]  # æœ€å¤šè¿”å›10ä¸ªä½œè€…

    def _detect_programming_languages(self, repo_path: Path) -> List[str]:
        """æ£€æµ‹é¡¹ç›®ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€"""
        languages = set()

        # é€šè¿‡æ–‡ä»¶æ‰©å±•åè¯†åˆ«ç¼–ç¨‹è¯­è¨€
        extension_mapping = {
            ".py": "Python",
            ".js": "JavaScript",
            ".ts": "TypeScript",
            ".java": "Java",
            ".cpp": "C++",
            ".c": "C",
            ".cs": "C#",
            ".go": "Go",
            ".rs": "Rust",
            ".rb": "Ruby",
            ".php": "PHP",
            ".swift": "Swift",
            ".kt": "Kotlin",
            ".R": "R",
            ".r": "R",
            ".sql": "SQL",
            ".sh": "Shell",
            ".pl": "Perl",
            ".lua": "Lua",
            ".dart": "Dart",
            ".scala": "Scala",
            ".m": "Objective-C",
            ".mm": "Objective-C++",
            ".groovy": "Groovy",
            ".hs": "Haskell",
            ".clj": "Clojure",
            ".ex": "Elixir",
            ".exs": "Elixir",
            ".erl": "Erlang",
            ".fs": "F#",
            ".ml": "OCaml",
            ".mli": "OCaml",
        }

        # éå†é¡¹ç›®æ–‡ä»¶
        for root, dirs, files in os.walk(repo_path):
            # è·³è¿‡éšè—ç›®å½•å’Œnode_modulesç­‰
            dirs[:] = [
                d
                for d in dirs
                if not d.startswith(".")
                and d not in ["node_modules", "venv", "__pycache__"]
            ]

            for file in files:
                _, ext = os.path.splitext(file)
                if ext in extension_mapping:
                    languages.add(extension_mapping[ext])

        # æ£€æŸ¥ç‰¹æ®Šæ–‡ä»¶
        if (repo_path / "Cargo.toml").exists():
            languages.add("Rust")
        if (repo_path / "go.mod").exists():
            languages.add("Go")
        if (repo_path / "package.json").exists():
            languages.add("JavaScript")
        if (
            (repo_path / "requirements.txt").exists()
            or (repo_path / "setup.py").exists()
            or (repo_path / "pyproject.toml").exists()
        ):
            languages.add("Python")

        return list(languages)

    def _detect_frameworks(self, repo_path: Path) -> List[str]:
        """æ£€æµ‹é¡¹ç›®ä½¿ç”¨çš„æ¡†æ¶å’Œåº“"""
        frameworks = []

        # Pythonæ¡†æ¶æ£€æµ‹
        if (repo_path / "requirements.txt").exists():
            content = self.read_file_content(repo_path, "requirements.txt") or ""
            python_frameworks = {
                "django": "Django",
                "flask": "Flask",
                "fastapi": "FastAPI",
                "pyramid": "Pyramid",
                "tornado": "Tornado",
                "dash": "Dash",
                "streamlit": "Streamlit",
                "numpy": "NumPy",
                "pandas": "Pandas",
                "scikit-learn": "Scikit-learn",
                "tensorflow": "TensorFlow",
                "torch": "PyTorch",
                "keras": "Keras",
            }
            for package, framework in python_frameworks.items():
                if package in content.lower():
                    frameworks.append(framework)

        if (repo_path / "setup.py").exists() or (repo_path / "pyproject.toml").exists():
            content = (
                self.read_file_content(repo_path, "setup.py")
                or self.read_file_content(repo_path, "pyproject.toml")
                or ""
            )
            python_frameworks = {
                "django": "Django",
                "flask": "Flask",
                "fastapi": "FastAPI",
                "pyramid": "Pyramid",
                "tornado": "Tornado",
                "dash": "Dash",
                "streamlit": "Streamlit",
            }
            for package, framework in python_frameworks.items():
                if package in content.lower():
                    frameworks.append(framework)

        # JavaScript/Node.jsæ¡†æ¶æ£€æµ‹
        if (repo_path / "package.json").exists():
            content = self.read_file_content(repo_path, "package.json") or ""
            js_frameworks = {
                "react": "React",
                "vue": "Vue.js",
                "angular": "Angular",
                "express": "Express",
                "next": "Next.js",
                "nuxt": "Nuxt.js",
                "svelte": "Svelte",
                "ember": "Ember.js",
            }
            for package, framework in js_frameworks.items():
                if package in content.lower():
                    frameworks.append(framework)

        # Javaæ¡†æ¶æ£€æµ‹
        if (repo_path / "pom.xml").exists() or (repo_path / "build.gradle").exists():
            content = (
                self.read_file_content(repo_path, "pom.xml")
                or self.read_file_content(repo_path, "build.gradle")
                or ""
            )
            java_frameworks = {
                "spring": "Spring",
                "hibernate": "Hibernate",
                "struts": "Struts",
                "play": "Play Framework",
            }
            for framework_key, framework_name in java_frameworks.items():
                if framework_key in content.lower():
                    frameworks.append(framework_name)

        return list(set(frameworks))  # å»é‡

    def _analyze_directory_structure(self, repo_path: Path) -> Dict[str, str]:
        """åˆ†æç›®å½•ç»“æ„"""
        directory_structure = {}

        def analyze_dir(path: Path, prefix: str = ""):
            if path.name.startswith(".") or path.name in [
                "node_modules",
                "venv",
                "__pycache__",
                ".git",
            ]:
                return

            for item in path.iterdir():
                if item.is_dir():
                    # è®°å½•ç›®å½•
                    dir_path = f"{prefix}/{item.name}" if prefix else item.name
                    # å°è¯•è¯†åˆ«ç›®å½•ç”¨é€”
                    purpose = self._identify_directory_purpose(item)
                    directory_structure[dir_path] = purpose
                    # é€’å½’åˆ†æå­ç›®å½•ï¼Œä½†é™åˆ¶æ·±åº¦
                    if prefix.count("/") < 2:  # é™åˆ¶é€’å½’æ·±åº¦
                        analyze_dir(item, dir_path)
                elif item.is_file() and prefix == "":  # æ ¹ç›®å½•çš„æ–‡ä»¶
                    directory_structure[item.name] = "æ ¹ç›®å½•æ–‡ä»¶"

        analyze_dir(repo_path)
        return directory_structure

    def _identify_directory_purpose(self, dir_path: Path) -> str:
        """è¯†åˆ«ç›®å½•ç”¨é€”"""
        dir_name = dir_path.name.lower()

        purpose_mapping = {
            "src": "æºä»£ç ç›®å½•",
            "source": "æºä»£ç ç›®å½•",
            "lib": "åº“æ–‡ä»¶ç›®å½•",
            "libs": "åº“æ–‡ä»¶ç›®å½•",
            "library": "åº“æ–‡ä»¶ç›®å½•",
            "bin": "å¯æ‰§è¡Œæ–‡ä»¶ç›®å½•",
            "dist": "æ„å»ºè¾“å‡ºç›®å½•",
            "build": "æ„å»ºç›®å½•",
            "out": "è¾“å‡ºç›®å½•",
            "target": "Maven/Gradleæ„å»ºç›®å½•",
            "test": "æµ‹è¯•ç›®å½•",
            "tests": "æµ‹è¯•ç›®å½•",
            "spec": "æµ‹è¯•ç›®å½•",
            "specs": "æµ‹è¯•ç›®å½•",
            "docs": "æ–‡æ¡£ç›®å½•",
            "doc": "æ–‡æ¡£ç›®å½•",
            "documentation": "æ–‡æ¡£ç›®å½•",
            "config": "é…ç½®æ–‡ä»¶ç›®å½•",
            "conf": "é…ç½®æ–‡ä»¶ç›®å½•",
            "cfg": "é…ç½®æ–‡ä»¶ç›®å½•",
            "scripts": "è„šæœ¬ç›®å½•",
            "script": "è„šæœ¬ç›®å½•",
            "tools": "å·¥å…·ç›®å½•",
            "utils": "å·¥å…·ç›®å½•",
            "util": "å·¥å…·ç›®å½•",
            "examples": "ç¤ºä¾‹ç›®å½•",
            "example": "ç¤ºä¾‹ç›®å½•",
            "demo": "æ¼”ç¤ºç›®å½•",
            "demos": "æ¼”ç¤ºç›®å½•",
            "assets": "èµ„æºæ–‡ä»¶ç›®å½•",
            "static": "é™æ€æ–‡ä»¶ç›®å½•",
            "public": "å…¬å…±èµ„æºç›®å½•",
            "templates": "æ¨¡æ¿ç›®å½•",
            "views": "è§†å›¾ç›®å½•",
            "controllers": "æ§åˆ¶å™¨ç›®å½•",
            "models": "æ¨¡å‹ç›®å½•",
            "services": "æœåŠ¡ç›®å½•",
            "api": "APIæ¥å£ç›®å½•",
            "routes": "è·¯ç”±ç›®å½•",
        }

        return purpose_mapping.get(dir_name, "æ™®é€šç›®å½•")

    def _identify_main_components(self, repo_path: Path) -> List[str]:
        """è¯†åˆ«ä¸»è¦ç»„ä»¶"""
        components = []

        # é€šè¿‡ç›®å½•ç»“æ„è¯†åˆ«ç»„ä»¶
        for item in repo_path.iterdir():
            if (
                item.is_dir()
                and not item.name.startswith(".")
                and item.name not in ["node_modules", "venv", "__pycache__", ".git"]
            ):
                components.append(item.name)

        # é€šè¿‡ç‰¹æ®Šæ–‡ä»¶è¯†åˆ«ç»„ä»¶
        special_files = {
            "Dockerfile": "Dockerå®¹å™¨",
            "docker-compose.yml": "Dockerå®¹å™¨ç¼–æ’",
            "docker-compose.yaml": "Dockerå®¹å™¨ç¼–æ’",
            "Makefile": "æ„å»ºå·¥å…·",
            "CMakeLists.txt": "CMakeæ„å»ºé…ç½®",
            "pom.xml": "Mavené¡¹ç›®é…ç½®",
            "build.gradle": "Gradleé¡¹ç›®é…ç½®",
            "webpack.config.js": "Webpackæ‰“åŒ…é…ç½®",
            "vite.config.js": "Viteæ„å»ºé…ç½®",
            "package.json": "Node.jsé¡¹ç›®é…ç½®",
        }

        for file_name, component in special_files.items():
            if (repo_path / file_name).exists():
                components.append(component)

        return list(set(components))  # å»é‡

    def _identify_entry_points(self, repo_path: Path) -> List[str]:
        """è¯†åˆ«é¡¹ç›®å…¥å£ç‚¹"""
        entry_points = []

        # Pythoné¡¹ç›®å…¥å£ç‚¹
        if (repo_path / "setup.py").exists():
            content = self.read_file_content(repo_path, "setup.py") or ""
            entry_matches = re.findall(
                r"entry_points.*?console_scripts.*?=\s*\[(.*?)\]",
                content,
                re.DOTALL | re.IGNORECASE,
            )
            if entry_matches:
                entry_points.append("Python CLIå‘½ä»¤")

        # æŸ¥æ‰¾mainæ–‡ä»¶
        for item in repo_path.iterdir():
            if item.is_file():
                if item.name.startswith("main.") or "main" in item.name:
                    entry_points.append(f"ä¸»ç¨‹åºæ–‡ä»¶: {item.name}")
                elif item.name == "app.py" or item.name == "application.py":
                    entry_points.append(f"åº”ç”¨å…¥å£: {item.name}")

        # æŸ¥æ‰¾å¯æ‰§è¡Œè„šæœ¬
        scripts_dir = repo_path / "scripts"
        if scripts_dir.exists() and scripts_dir.is_dir():
            for script in scripts_dir.iterdir():
                if script.is_file() and script.stat().st_mode & 0o111:  # å¯æ‰§è¡Œæ–‡ä»¶
                    entry_points.append(f"å¯æ‰§è¡Œè„šæœ¬: {script.name}")

        # package.jsonä¸­çš„scripts
        if (repo_path / "package.json").exists():
            content = self.read_file_content(repo_path, "package.json") or ""
            if '"start"' in content or '"dev"' in content:
                entry_points.append("Node.jsåº”ç”¨å…¥å£")

        return entry_points

    def _identify_config_files(self, repo_path: Path) -> List[str]:
        """è¯†åˆ«é…ç½®æ–‡ä»¶"""
        config_files = []

        common_configs = [
            "config.json",
            "config.yaml",
            "config.yml",
            "config.toml",
            "settings.json",
            "settings.yaml",
            "settings.yml",
            ".env",
            ".env.local",
            ".env.production",
            "application.properties",
            "application.yml",
            "web.xml",
            "server.xml",
            "nginx.conf",
            "apache.conf",
            "docker-compose.yml",
            "docker-compose.yaml",
        ]

        for config in common_configs:
            if (repo_path / config).exists():
                config_files.append(config)

        # æŸ¥æ‰¾é…ç½®ç›®å½•ä¸­çš„æ–‡ä»¶
        config_dirs = ["config", "conf", "cfg"]
        for dir_name in config_dirs:
            config_dir = repo_path / dir_name
            if config_dir.exists() and config_dir.is_dir():
                for config_file in config_dir.iterdir():
                    if config_file.is_file():
                        config_files.append(f"{dir_name}/{config_file.name}")

        return config_files

    def _analyze_test_structure(self, repo_path: Path) -> Dict[str, str]:
        """åˆ†ææµ‹è¯•ç»“æ„"""
        test_structure = {}

        # æŸ¥æ‰¾æµ‹è¯•ç›®å½•
        test_dirs = ["test", "tests", "spec", "specs"]
        for dir_name in test_dirs:
            test_dir = repo_path / dir_name
            if test_dir.exists() and test_dir.is_dir():
                # åˆ†ææµ‹è¯•ç›®å½•ä¸­çš„æ–‡ä»¶å’Œå­ç›®å½•
                for item in test_dir.iterdir():
                    if item.is_dir():
                        test_structure[f"{dir_name}/{item.name}"] = "æµ‹è¯•å­ç›®å½•"
                    elif item.is_file():
                        test_structure[f"{dir_name}/{item.name}"] = "æµ‹è¯•æ–‡ä»¶"

        # æŸ¥æ‰¾æ ¹ç›®å½•çš„æµ‹è¯•æ–‡ä»¶
        for item in repo_path.iterdir():
            if item.is_file() and "test" in item.name.lower():
                test_structure[item.name] = "æ ¹ç›®å½•æµ‹è¯•æ–‡ä»¶"

        return test_structure

    def analyze_security(self, repo_path: Path) -> Optional[SecurityAnalysis]:
        """åˆ†æä»“åº“å®‰å…¨æ€§ - MVPå®ç°"""
        print(f"ğŸ” å¼€å§‹å®‰å…¨åˆ†æ: {repo_path.name}")
        
        try:
            from .security_analyzer import SecurityAnalyzer
            
            analyzer = SecurityAnalyzer(repo_path)
            security_analysis = analyzer.analyze_security()
            
            if security_analysis:
                print(f"âœ… å®‰å…¨åˆ†æå®Œæˆ: {security_analysis.total_high_risk} é«˜é£é™©, "
                      f"{security_analysis.total_medium_risk} ä¸­é£é™©, "
                      f"{security_analysis.total_low_risk} ä½é£é™©")
            else:
                print("âš ï¸ å®‰å…¨åˆ†ææœªè¿”å›ç»“æœ")
                
            return security_analysis
            
        except ImportError:
            print("âš ï¸ å®‰å…¨åˆ†ææ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œè·³è¿‡å®‰å…¨æ£€æŸ¥")
            return None
        except Exception as e:
            print(f"âš ï¸ å®‰å…¨åˆ†æå¤±è´¥: {e}")
            return None
